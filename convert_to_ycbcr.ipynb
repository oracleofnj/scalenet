{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.custom_transformers as custom_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \\#1: Change the image from RGB to YCbCr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./image_files',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=False, num_workers=0)\n",
    "gen = iter(trainloader)\n",
    "images_cpu, labels_cpu = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image = images_cpu[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(one_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_to_ycbyr = torch.tensor([\n",
    "    [0.299, 0.587, 0.114],\n",
    "    [-0.169, -0.331, 0.5],\n",
    "    [0.5, -0.419, -0.081]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4430, -0.2500,  0.0405])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(rgb_to_ycbyr, torch.tensor([0.5, 0.5, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 0.7059, 0.7765])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_image[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7022,  0.0419, -0.0253])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(rgb_to_ycbyr, one_image[:,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R is the conversion matrix\n",
    "\n",
    "P is the picture (C, H, W)\n",
    "\n",
    "$$y_{ikl} = \\sum_j R_{ij} P_{jkl}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image_ycbcr = torch.einsum('ij,jkl->ikl', [rgb_to_ycbyr, one_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7022,  0.0419, -0.0253])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_image_ycbcr[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToYCbYr(object):\n",
    "    rgb_to_ycbyr_matrix = torch.tensor([\n",
    "        [0.299, 0.587, 0.114],\n",
    "        [-0.169, -0.331, 0.5],\n",
    "        [0.5, -0.419, -0.081]\n",
    "    ])\n",
    "    \n",
    "    def __call__(self, pic):\n",
    "        return torch.einsum('ij,jkl->ikl', [ToYCbYr.rgb_to_ycbyr_matrix, pic])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7022,  0.0419, -0.0253])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToYCbYr()(one_image)[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7022,  0.0419, -0.0253])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_transformers.ToYCbYr()(one_image)[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_ycbcr = torchvision.datasets.CIFAR10(\n",
    "    root='./image_files',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        custom_transformers.ToYCbYr()\n",
    "    ])\n",
    ")\n",
    "trainloader_ycbcr = torch.utils.data.DataLoader(trainset_ycbcr, batch_size=16, shuffle=False, num_workers=0)\n",
    "gen_ycbcr = iter(trainloader_ycbcr)\n",
    "images_cpu_ycbcr, labels_cpu_ycbcr = next(gen_ycbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.4007e-01,  1.7643e-01,  1.8835e-01,  ...,  5.3740e-01,\n",
       "           5.1157e-01,  5.0503e-01],\n",
       "         [ 7.3741e-02,  0.0000e+00,  3.9522e-02,  ...,  3.7138e-01,\n",
       "           3.5295e-01,  3.6880e-01],\n",
       "         [ 9.3949e-02,  3.4875e-02,  1.2318e-01,  ...,  3.5408e-01,\n",
       "           3.5642e-01,  3.1463e-01],\n",
       "         ...,\n",
       "         [ 6.7814e-01,  6.0308e-01,  6.1440e-01,  ...,  5.2506e-01,\n",
       "           1.4015e-01,  1.4935e-01],\n",
       "         [ 5.7395e-01,  5.0477e-01,  5.6299e-01,  ...,  5.9846e-01,\n",
       "           2.7166e-01,  2.3453e-01],\n",
       "         [ 5.9088e-01,  5.3596e-01,  5.7566e-01,  ...,  7.3942e-01,\n",
       "           4.8624e-01,  3.8819e-01]],\n",
       "\n",
       "        [[ 3.9490e-03,  2.7448e-05, -1.1129e-02,  ..., -6.4290e-02,\n",
       "          -6.2992e-02, -5.7082e-02],\n",
       "         [ 2.6510e-03,  0.0000e+00, -2.2314e-02,  ..., -8.7902e-02,\n",
       "          -8.8565e-02, -8.2020e-02],\n",
       "         [-6.5451e-03, -1.9690e-02, -5.1835e-02,  ..., -8.9200e-02,\n",
       "          -9.0526e-02, -8.4643e-02],\n",
       "         ...,\n",
       "         [-1.7028e-01, -2.6515e-01, -2.8923e-01,  ..., -1.4142e-01,\n",
       "          -6.3627e-02, -4.0043e-02],\n",
       "         [-1.1149e-01, -1.9196e-01, -2.5136e-01,  ..., -1.2974e-01,\n",
       "          -7.8098e-02, -5.7137e-02],\n",
       "         [-7.6773e-02, -9.4475e-02, -1.3236e-01,  ..., -1.0748e-01,\n",
       "          -8.8537e-02, -5.9761e-02]],\n",
       "\n",
       "        [[-6.2000e-03, -5.5647e-03,  5.5098e-03,  ...,  5.8604e-02,\n",
       "           6.0247e-02,  5.3729e-02],\n",
       "         [-7.8431e-03,  0.0000e+00,  2.2149e-02,  ...,  7.9110e-02,\n",
       "           8.1071e-02,  7.8157e-02],\n",
       "         [ 2.9137e-03,  1.9871e-02,  4.9173e-02,  ...,  7.7467e-02,\n",
       "           8.1388e-02,  8.0435e-02],\n",
       "         ...,\n",
       "         [ 9.8016e-02,  1.3192e-01,  1.1543e-01,  ...,  7.2953e-02,\n",
       "           5.6643e-02,  4.1702e-02],\n",
       "         [ 9.4051e-02,  1.2377e-01,  1.1856e-01,  ...,  8.7741e-02,\n",
       "           7.7522e-02,  6.4859e-02],\n",
       "         [ 7.3600e-02,  8.7588e-02,  9.0020e-02,  ...,  7.6722e-02,\n",
       "           7.5506e-02,  6.7137e-02]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_cpu_ycbcr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.4007e-01,  1.7643e-01,  1.8835e-01,  ...,  5.3740e-01,\n",
       "           5.1157e-01,  5.0503e-01],\n",
       "         [ 7.3741e-02,  0.0000e+00,  3.9522e-02,  ...,  3.7138e-01,\n",
       "           3.5295e-01,  3.6880e-01],\n",
       "         [ 9.3949e-02,  3.4875e-02,  1.2318e-01,  ...,  3.5408e-01,\n",
       "           3.5642e-01,  3.1463e-01],\n",
       "         ...,\n",
       "         [ 6.7814e-01,  6.0308e-01,  6.1440e-01,  ...,  5.2506e-01,\n",
       "           1.4015e-01,  1.4935e-01],\n",
       "         [ 5.7395e-01,  5.0477e-01,  5.6299e-01,  ...,  5.9846e-01,\n",
       "           2.7166e-01,  2.3453e-01],\n",
       "         [ 5.9088e-01,  5.3596e-01,  5.7566e-01,  ...,  7.3942e-01,\n",
       "           4.8624e-01,  3.8819e-01]],\n",
       "\n",
       "        [[ 3.9490e-03,  2.7448e-05, -1.1129e-02,  ..., -6.4290e-02,\n",
       "          -6.2992e-02, -5.7082e-02],\n",
       "         [ 2.6510e-03,  0.0000e+00, -2.2314e-02,  ..., -8.7902e-02,\n",
       "          -8.8565e-02, -8.2020e-02],\n",
       "         [-6.5451e-03, -1.9690e-02, -5.1835e-02,  ..., -8.9200e-02,\n",
       "          -9.0526e-02, -8.4643e-02],\n",
       "         ...,\n",
       "         [-1.7028e-01, -2.6515e-01, -2.8923e-01,  ..., -1.4142e-01,\n",
       "          -6.3627e-02, -4.0043e-02],\n",
       "         [-1.1149e-01, -1.9196e-01, -2.5136e-01,  ..., -1.2974e-01,\n",
       "          -7.8098e-02, -5.7137e-02],\n",
       "         [-7.6773e-02, -9.4475e-02, -1.3236e-01,  ..., -1.0748e-01,\n",
       "          -8.8537e-02, -5.9761e-02]],\n",
       "\n",
       "        [[-6.2000e-03, -5.5647e-03,  5.5098e-03,  ...,  5.8604e-02,\n",
       "           6.0247e-02,  5.3729e-02],\n",
       "         [-7.8431e-03,  0.0000e+00,  2.2149e-02,  ...,  7.9110e-02,\n",
       "           8.1071e-02,  7.8157e-02],\n",
       "         [ 2.9137e-03,  1.9871e-02,  4.9173e-02,  ...,  7.7467e-02,\n",
       "           8.1388e-02,  8.0435e-02],\n",
       "         ...,\n",
       "         [ 9.8016e-02,  1.3192e-01,  1.1543e-01,  ...,  7.2953e-02,\n",
       "           5.6643e-02,  4.1702e-02],\n",
       "         [ 9.4051e-02,  1.2377e-01,  1.1856e-01,  ...,  8.7741e-02,\n",
       "           7.7522e-02,  6.4859e-02],\n",
       "         [ 7.3600e-02,  8.7588e-02,  9.0020e-02,  ...,  7.6722e-02,\n",
       "           7.5506e-02,  6.7137e-02]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_transformers.ToYCbYr()(images_cpu[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
